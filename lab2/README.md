# Лабораторная работа 7

Веб-приложение на базе фреймворка Litestar с использованием Dependency Injection, SQLAlchemy ORM, RabbitMQ для асинхронной обработки сообщений, Redis для кэширования данных о пользователях, продуктах и заказах, и TaskIQ для планирования и выполнения периодических задач.

## Оглавление

- [Быстрый старт](#быстрый-старт)
- [Установка и запуск](#установка-и-запуск)
  - [Вариант 1: Запуск через Docker Compose (Рекомендуется)](#вариант-1-запуск-через-docker-compose-рекомендуется)
  - [Вариант 2: Локальный запуск (для разработки)](#вариант-2-локальный-запуск-для-разработки)
- [Доступ к сервисам](#доступ-к-сервисам)
- [API Документация](#api-документация)
- [API Эндпоинты](#api-эндпоинты)
  - [Получить пользователя по ID](#получить-пользователя-по-id)
  - [Получить список пользователей](#получить-список-пользователей)
  - [Создать пользователя](#создать-пользователя)
  - [Обновить пользователя](#обновить-пользователя)
  - [Удалить пользователя](#удалить-пользователя)
  - [Получить отчеты](#получить-отчеты)
- [Разработка](#разработка)
  - [Линтеры и форматеры](#линтеры-и-форматеры)
  - [Работа с Docker](#работа-с-docker)
  - [Доступ к базе данных](#доступ-к-базе-данных)
- [Структура данных](#структура-данных)
- [Обработка ошибок](#обработка-ошибок)

## Быстрый старт

```bash
# 1. Создайте .env файл (см. раздел "Установка и запуск")
# 2. Запустите всё одной командой:
docker compose up --build

# 3. Приложение доступно по адресу:
# http://localhost:8000
# http://localhost:8000/docs (API документация)
```

## Установка и запуск

### Вариант 1: Запуск через Docker Compose (Рекомендуется)
#### 1. Клонирование репозитория

```bash
git clone <repository_url>
cd lab2
```

#### 2. Настройка переменных окружения

Создайте файл `.env` в корне проекта:

```env
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin
POSTGRES_DB=lab_db2

PGADMIN_DEFAULT_EMAIL=admin@lab2.com
PGADMIN_DEFAULT_PASSWORD=admin

DB_HOST=db
DB_PORT=5432
HOST=0.0.0.0
PORT=8000

# RabbitMQ настройки
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_VHOST=local
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest

# Redis настройки
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_DECODE_RESPONSES=true
```

> **Примечание:** `DATABASE_URL` для контейнера настраивается автоматически в `docker-compose.yml`. Переменные `DB_HOST` и `DB_PORT` используются в `entrypoint.sh` для ожидания готовности базы данных.

#### 3. Сборка и запуск всех сервисов

```bash
# Сборка образа и запуск
docker compose up --build

# Или в фоновом режиме
docker compose up --build -d
```

Эта команда автоматически:
- Соберёт Docker образ приложения (используя `Dockerfile`)
- Запустит PostgreSQL базу данных
- Запустит PgAdmin
- Запустит RabbitMQ брокер сообщений
- Запустит Redis для кэширования
- Применит миграции базы данных через `entrypoint.sh`
- Запустит веб-приложение (REST API)
- Запустит RabbitMQ worker для обработки сообщений

**Примечание:** При первом запуске или при изменении `Dockerfile` используйте флаг `--build` для пересборки образа. Скрипт `entrypoint.sh` автоматически ожидает готовности базы данных и применяет миграции перед запуском приложения.

#### 4. Проверка статуса

```bash
docker compose ps
```

Все сервисы должны быть в статусе `Up`:
- `app_lab3` - веб-приложение (REST API) на порту `8000`
- `rabbitmq_worker_lab2` - RabbitMQ worker для обработки сообщений
- `scheduler_lab2` - TaskIQ планировщик задач
- `taskiq_worker_lab2` - TaskIQ worker для обработки запланированных задач
- `db_postgres_lab2` - PostgreSQL на порту `5433`
- `pgadmin4_lab2` - PgAdmin на порту `8081`
- `rabbitmq_lab2` - RabbitMQ на портах `5672` (AMQP) и `15672` (Management UI)
- `redis` - Redis для кэширования на порту `6379`

#### 5. Просмотр логов

```bash
# Все логи
docker compose logs -f

# Только приложение
docker compose logs -f app

# Только база данных
docker compose logs -f db

# Только RabbitMQ
docker compose logs -f rabbitmq

# Только RabbitMQ worker
docker compose logs -f rabbitmq_worker

# Только TaskIQ scheduler
docker compose logs -f scheduler

# Только TaskIQ worker
docker compose logs -f taskiq_worker

# Только Redis
docker compose logs -f redis
```

#### 6. Остановка сервисов

```bash
docker compose down
```

Для полной очистки (включая volumes):

```bash
docker compose down -v
```

---

### Вариант 2: Локальный запуск (для разработки)

без докера

#### 1. Клонирование репозитория

```bash
git clone <repository_url>
cd lab2
```

#### 2. Настройка переменных окружения

Создайте файл `.env` в корне проекта:

```env
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin
POSTGRES_DB=lab_db2

PGADMIN_DEFAULT_EMAIL=admin@lab2.com
PGADMIN_DEFAULT_PASSWORD=admin

DATABASE_URL=postgresql+asyncpg://admin:admin@localhost:5433/lab_db2
```

#### 3. Установка зависимостей

```bash
uv sync
```

#### 4. Запуск базы данных

```bash
docker compose up -d db pgadmin
```

Это запустит только:
- PostgreSQL на порту `5433`
- PgAdmin на порту `8081`

#### 5. Применение миграций

```bash
cd app
../.venv/bin/alembic upgrade head
cd ..
```

#### 6. Запуск приложения

```bash
python main.py
```

Приложение будет доступно по адресу: `http://localhost:8000`

---

### Доступ к сервисам

После запуска приложение и сервисы будут доступны по следующим адресам:

- **Веб-приложение**: http://localhost:8000
- **API документация (Swagger)**: http://localhost:8000/docs
- **PgAdmin**: http://localhost:8081
- **PostgreSQL**: localhost:5433
- **RabbitMQ Management UI**: http://localhost:15672 (логин: `guest`, пароль: `guest`)
- **RabbitMQ AMQP**: localhost:5672
- **Redis**: localhost:6379

## API Документация

После запуска приложения доступна интерактивная документация:

- **Swagger UI**: http://localhost:8000/docs
- **OpenAPI JSON**: http://localhost:8000/schema/openapi.json

## API Эндпоинты

### Получить пользователя по ID

```http
GET /users/{user_id}
```

**Параметры:**
- `user_id` (int, path) - ID пользователя (должен быть > 0)

**Ответ:**
- `200 OK` - Пользователь найден
- `404 Not Found` - Пользователь не найден

**Пример:**
```bash
curl http://localhost:8000/users/1
```

### Получить список пользователей

```http
GET /users?count=10&page=1
```

**Query параметры:**
- `count` (int, optional) - Количество записей на странице (1-100, по умолчанию 10)
- `page` (int, optional) - Номер страницы (≥1, по умолчанию 1)

**Ответ:**
```json
{
  "users": [
    {
      "id": 1,
      "username": "john_doe",
      "email": "john@example.com",
      "description": "Software developer",
      "created_at": "2024-01-01T12:00:00",
      "updated_at": "2024-01-02T10:00:00"
    }
  ],
  "total": 25
}
```

**Пример:**
```bash
curl "http://localhost:8000/users?count=5&page=2"
```

### Создать пользователя

```http
POST /users
Content-Type: application/json
```

**Тело запроса:**
```json
{
  "username": "jane_doe",
  "email": "jane@example.com",
  "description": "Designer"
}
```

**Ответ:**
- `201 Created` - Пользователь создан
- `400 Bad Request` - Ошибка валидации (email или username уже существует)
- `422 Unprocessable Entity` - Невалидные данные

**Пример:**
```bash
curl -X POST http://localhost:8000/users \
  -H "Content-Type: application/json" \
  -d '{
    "username": "jane_doe",
    "email": "jane@example.com",
    "description": "Designer"
  }'
```

### Обновить пользователя

```http
PUT /users/{user_id}
Content-Type: application/json
```

**Параметры:**
- `user_id` (int, path) - ID пользователя

**Тело запроса (все поля опциональные):**
```json
{
  "email": "newemail@example.com"
}
```

**Ответ:**
- `200 OK` - Пользователь обновлен
- `404 Not Found` - Пользователь не найден
- `400 Bad Request` - Email или username уже существует
- `422 Unprocessable Entity` - Невалидные данные

**Пример:**
```bash
curl -X PUT http://localhost:8000/users/1 \
  -H "Content-Type: application/json" \
  -d '{"email": "newemail@example.com"}'
```

### Удалить пользователя

```http
DELETE /users/{user_id}
```

**Параметры:**
- `user_id` (int, path) - ID пользователя

**Ответ:**
- `204 No Content` - Пользователь удален
- `404 Not Found` - Пользователь не найден

**Пример:**
```bash
curl -X DELETE http://localhost:8000/users/1
```

### Получить отчеты

```http
GET /report?report_date=2025-12-16
```

**Query параметры:**
- `report_date` (date, optional) - Дата для получения отчетов в формате `YYYY-MM-DD` (по умолчанию текущая дата)

**Ответ:**
```json
[
  {
    "id": 1,
    "report_at": "2025-12-16",
    "order_id": 5,
    "count_product": 4,
    "created_at": "2025-12-16T12:50:00.089033"
  },
  {
    "id": 2,
    "report_at": "2025-12-16",
    "order_id": 6,
    "count_product": 3,
    "created_at": "2025-12-16T12:50:00.091522"
  }
]
```

**Примеры:**
```bash
# Получить отчеты за сегодня
curl http://localhost:8000/report

# Получить отчеты за конкретную дату
curl "http://localhost:8000/report?report_date=2025-12-16"
```

**Описание:**
Эндпоинт возвращает список отчетов по заказам за указанную дату. Отчеты автоматически создаются планировщиком задач TaskIQ каждый день в полночь. Каждый отчет содержит информацию о заказе и общем количестве продукции в заказе.

## Разработка

### Линтеры и форматеры

Проект использует `pre-commit` для автоматической проверки кода перед коммитом.

#### Установка pre-commit

```bash
# Установка хуков
uv run pre-commit install
```

#### Ручной запуск проверок

```bash
# Запуск всех проверок на всех файлах
uv run pre-commit run --all-files

# Форматирование кода
uv run black app

# Сортировка импортов
uv run isort app

# Проверка качества кода (без миграций)
uv run pylint app --ignore=migrations
```

#### Конфигурация

- **Black** и **isort**: настройки в `pyproject.toml`
- **Pylint**: настройки в `.pylintrc`
- **Pre-commit**: настройки в `.pre-commit-config.yaml`

Миграции Alembic исключены из проверки pylint, так как они генерируются автоматически.

### Работа с Docker

#### Сборка образа

```bash
# Сборка образа приложения
docker compose build

# Сборка с пересозданием кеша
docker compose build --no-cache
```

#### Entrypoint

При запуске контейнера используется `entrypoint.sh`, который:
1. Ожидает готовности базы данных (проверка через `netcat`)
2. Применяет миграции Alembic автоматически
3. Запускает приложение

#### Создание миграций

```bash
# В контейнере
docker compose exec app sh -c "cd app && uv run alembic revision --autogenerate -m 'описание изменений'"

# Локально
cd app
uv run alembic revision --autogenerate -m "описание изменений"
```

#### Перезапуск сервисов

```bash
# Перезапустить только приложение
docker compose restart app

# Перезапустить все сервисы
docker compose restart
```

### Доступ к базе данных

**Через PgAdmin:**
- URL: http://localhost:8081
- Email: admin@lab2.com
- Password: admin

### Доступ к Redis

**Через Redis CLI:**
```bash
# Подключение к Redis через Docker
docker compose exec redis redis-cli

# Или локально (если Redis доступен на localhost:6379)
redis-cli -h localhost -p 6379
```

**Полезные команды Redis CLI:**
```bash
# Проверка подключения
PING

# Просмотр всех ключей
KEYS *

# Просмотр ключей по шаблону
KEYS user:*
KEYS product:*

# Получение значения ключа
GET user:1

# Проверка TTL ключа (в секундах)
TTL user:1

# Просмотр информации о Redis
INFO

# Очистка всех данных (осторожно!)
FLUSHDB
```

**Переменные окружения для Redis:**
- `REDIS_HOST` - хост Redis (по умолчанию `redis` в Docker, `localhost` локально)
- `REDIS_PORT` - порт Redis (по умолчанию `6379`)
- `REDIS_DB` - номер базы данных (по умолчанию `0`)
- `REDIS_DECODE_RESPONSES` - автоматическая декодировка ответов в строки (по умолчанию `true`)

## Структура данных

### User (Пользователь)

| Поле | Тип | Описание |
|------|-----|----------|
| id | int | Уникальный идентификатор (autoincrement) |
| username | str | Имя пользователя (уникальное) |
| email | str | Email адрес (уникальный) |
| description | str \| None | Описание пользователя (опционально) |
| created_at | datetime | Дата и время создания |
| updated_at | datetime \| None | Дата и время последнего обновления |

## RabbitMQ

Проект использует RabbitMQ для асинхронной обработки сообщений о создании и обновлении продуктов и заказов.

### Архитектура

- **REST API** (Litestar): Получение данных (GET запросы)
- **RabbitMQ**: Создание и обновление данных (асинхронно через очереди)
- **RabbitMQ Worker**: Отдельный процесс для обработки сообщений из очередей

### Очереди

- `product` - очередь для создания продуктов
- `product_update` - очередь для обновления продуктов
- `order` - очередь для создания заказов
- `order_update` - очередь для обновления статуса заказов

### Использование Producer скрипта

Для отправки тестовых данных в RabbitMQ используйте producer скрипт:

```bash
# В Docker контейнере
docker compose exec app uv run python producer.py

# Локально (если RabbitMQ доступен на localhost:5672)
uv run python producer.py
```

Скрипт создаст:
- 5 тестовых продуктов
- 3 тестовых заказа

**Важно:** Перед запуском producer убедитесь, что в базе данных существуют:
- Пользователь с `user_id=1` (или установите `TEST_USER_ID` в переменных окружения)
- Адрес доставки с `delivery_address_id=1` (или установите `TEST_DELIVERY_ADDRESS_ID`)

### Веб-интерфейс RabbitMQ

Доступен по адресу: http://localhost:15672

- **Логин:** `guest`
- **Пароль:** `guest`

В интерфейсе можно:
- Просматривать очереди и их статистику
- Мониторить сообщения
- Проверять подключения и каналы

### Особенности обработки

1. **Создание заказов:**
   - Проверяется наличие всех товаров (`stock_quantity > 0`)
   - Если хотя бы один товар закончился (`stock_quantity == 0`), заказ отклоняется
   - При успешном создании заказа количество товаров на складе уменьшается

2. **Обновление продуктов:**
   - При обновлении проверяется, не закончился ли товар
   - Если `stock_quantity == 0`, в логах появляется предупреждение

3. **Получение данных:**
   - Все GET запросы работают через REST API (синхронно)
   - Создание и обновление доступно как через RabbitMQ, так и через REST API (для совместимости)

## Планировщик задач TaskIQ

Проект использует TaskIQ для планирования и выполнения периодических задач. TaskIQ - это распределенная система очередей задач с полной поддержкой асинхронности и планирования.

### Архитектура

Система планирования состоит из двух компонентов:

1. **TaskIQ Scheduler** (`scheduler_lab2`) - планировщик, который отправляет задачи в очередь по расписанию
2. **TaskIQ Worker** (`taskiq_worker_lab2`) - воркер, который обрабатывает задачи из очереди

### Функциональность

Планировщик автоматически выполняет следующие задачи:

- **Генерация отчетов по заказам** - каждый день в полночь (`0 0 * * *`) создаются отчеты по всем заказам за прошедший день
  - Для каждого заказа создается запись в таблице `reports`
  - Подсчитывается общее количество продукции в заказе
  - Отправляется сообщение в RabbitMQ с информацией о созданных отчетах

### Запуск планировщика

#### В Docker Compose

Планировщик и воркер запускаются автоматически при старте всех сервисов:

```bash
docker compose up -d
```

Проверка статуса:

```bash
docker compose ps scheduler taskiq_worker
```

#### Локальный запуск

**Запуск планировщика:**
```bash
cd lab2
uv run taskiq scheduler app.scheduler:scheduler
```

**Запуск воркера (в отдельном терминале):**
```bash
cd lab2
uv run taskiq worker app.scheduler:broker
```

**Важно:** Планировщик и воркер должны работать одновременно:
- Планировщик отправляет задачи по расписанию
- Воркер обрабатывает задачи из очереди

### Мониторинг

**Просмотр логов планировщика:**
```bash
docker compose logs -f scheduler
```

**Просмотр логов воркера:**
```bash
docker compose logs -f taskiq_worker
```

**Ожидаемые сообщения в логах:**
- `Starting report generation for date: YYYY-MM-DD`
- `Created X reports for date YYYY-MM-DD`
- `Sent report message to RabbitMQ queue 'report' for date YYYY-MM-DD`

### Настройка расписания

Расписание задач настраивается в файле `app/scheduler.py` через cron-выражения:

```python
@broker.task(
    schedule=[
        {
            "cron": "0 0 * * *",  # Каждый день в полночь
            "cron_offset": None,
            "args": [],
            "kwargs": {},
        }
    ]
)
async def my_scheduled_task(...):
    # Логика задачи
```

**Примеры cron-выражений:**
- `"0 0 * * *"` - каждый день в полночь
- `"0 */6 * * *"` - каждые 6 часов
- `"0 0 * * 1"` - каждый понедельник в полночь
- `"*/5 * * * *"` - каждые 5 минут (для тестирования)

### Источники расписаний

TaskIQ поддерживает два типа источников расписаний:

1. **LabelScheduleSource** - статические расписания, определенные через декораторы задач
2. **RedisScheduleSource** - динамические расписания, хранящиеся в Redis (можно изменять без перезапуска)

### Проверка работы

**Проверка создания отчетов в базе данных:**
```bash
docker exec -it db_postgres_lab2 psql -U admin -d lab_db2 -c \
  "SELECT id, report_at, order_id, count_product, created_at FROM reports ORDER BY created_at DESC LIMIT 10;"
```

**Проверка сообщений в RabbitMQ:**
1. Откройте http://localhost:15672
2. Перейдите в раздел "Queues"
3. Найдите очередь `report`
4. Проверьте наличие сообщений

**Тестирование API эндпоинта:**
```bash
# Получить отчеты за сегодня
curl http://localhost:8000/report

# Получить отчеты за конкретную дату
curl "http://localhost:8000/report?report_date=2025-12-16"
```

### Структура данных отчетов

| Поле | Тип | Описание |
|------|-----|----------|
| id | int | Уникальный идентификатор отчета |
| report_at | date | Дата отчета |
| order_id | int | ID заказа (ForeignKey к orders) |
| count_product | int | Общее количество продукции в заказе |
| created_at | datetime | Дата и время создания отчета |

### Очереди RabbitMQ

Планировщик отправляет сообщения в очередь `report` со следующей структурой:

```json
{
  "report_date": "2025-12-16",
  "reports_count": 3,
  "reports": [
    {
      "report_id": 1,
      "order_id": 5,
      "count_product": 4,
      "report_at": "2025-12-16"
    }
  ],
  "created_at": "2025-12-16T12:50:00.089033"
}
```

## Redis Кэширование

Проект использует Redis для кэширования данных пользователей и продукции, что значительно ускоряет доступ к часто запрашиваемым данным и снижает нагрузку на базу данных.

### Архитектура кэширования

Система использует стратегию **Cache-Aside** (Lazy Loading):

1. **При чтении данных:**
   - Сначала проверяется кэш Redis
   - Если данных нет в кэше (cache miss), запрос идет к базе данных
   - Полученные данные сохраняются в кэш для последующих запросов

2. **При обновлении пользователя:**
   - Обновление данных в базе данных
   - **Инвалидация кэша** (удаление данных из кэша)
   - При следующем запросе данные будут загружены из БД и сохранены в кэш

3. **При обновлении продукции:**
   - Обновление данных в базе данных
   - **Обновление кэша** (данные обновляются в кэше)
   - При следующем запросе данные сразу доступны из кэша

### Структура кэша

**Формат ключей:**
- Пользователи: `user:{id}` (например, `user:1`, `user:42`)
- Продукция: `product:{id}` (например, `product:1`, `product:100`)

**TTL (Time To Live):**
- **Пользователи**: 1 час (3600 секунд) - данные меняются редко
- **Продукция**: 10 минут (600 секунд) - данные могут меняться чаще

**Сериализация данных:**
- Данные хранятся в формате JSON
- Datetime объекты преобразуются в ISO строки для сериализации

### Преимущества кэширования

1. **Производительность:**
   - Запросы из кэша выполняются в разы быстрее, чем запросы к базе данных
   - Снижение нагрузки на PostgreSQL

2. **Масштабируемость:**
   - Redis может обрабатывать десятки тысяч запросов в секунду
   - Возможность горизонтального масштабирования

3. **Отказоустойчивость:**
   - При недоступности Redis приложение продолжает работать
   - Все запросы идут напрямую к базе данных
   - Ошибки кэширования не блокируют основную логику

### Стратегии инвалидации кэша

**Для пользователей (инвалидация):**
- При обновлении: данные удаляются из кэша
- При удалении: данные удаляются из кэша
- При следующем запросе: данные загружаются из БД и сохраняются в кэш

**Для продукции (обновление):**
- При обновлении: данные обновляются в кэше с новым TTL
- При удалении: данные удаляются из кэша
- При следующем запросе: данные сразу доступны из кэша

### Примеры использования Redis CLI

**Подключение к Redis:**
```bash
docker compose exec redis redis-cli
```

**Просмотр всех ключей:**
```bash
KEYS *
```

**Просмотр ключей пользователей:**
```bash
KEYS user:*
```

**Просмотр ключей продукции:**
```bash
KEYS product:*
```

**Проверка TTL ключа:**
```bash
# Для пользователя (должен быть ~3600 секунд)
TTL user:1

# Для продукции (должен быть ~600 секунд)
TTL product:1
```

**Просмотр значения ключа:**
```bash
# Получить данные пользователя
GET user:1

# Получить данные продукции
GET product:1
```

**Удаление ключа:**
```bash
DEL user:1
DEL product:1
```

**Проверка существования ключа:**
```bash
EXISTS user:1
```

**Просмотр информации о Redis:**
```bash
INFO
INFO memory
INFO stats
```

**Очистка всех данных (осторожно!):**
```bash
FLUSHDB
```

### Тестирование кэширования

Для тестирования кэширования используйте тестовый скрипт:

```bash
# Запуск тестов кэширования
uv run python test_redis_cache.py
```

Скрипт проверяет:
- Cache miss и cache hit для пользователей и продукции
- Инвалидацию кэша при обновлении пользователей
- Обновление кэша при обновлении продукции
- Корректность TTL для разных типов данных
- Производительность запросов с кэшем и без

### Мониторинг кэша

**Проверка статистики кэша:**
```bash
# В Redis CLI
INFO stats

# Просмотр количества ключей
DBSIZE

# Просмотр использования памяти
INFO memory
```

**Логирование:**
- Все операции с кэшем логируются в приложении
- Cache hits и cache misses логируются на уровне INFO/DEBUG
- Ошибки подключения к Redis логируются на уровне WARNING

## Обработка ошибок

| HTTP Статус | Описание |
|-------------|----------|
| 200 OK | Успешный запрос (GET, PUT) |
| 201 Created | Ресурс создан (POST) |
| 204 No Content | Ресурс удален (DELETE) |
| 400 Bad Request | Ошибка валидации (дублирующийся email/username) |
| 404 Not Found | Ресурс не найден |
| 422 Unprocessable Entity | Невалидные данные (Pydantic валидация) |
