# Лабораторная работа 7

Веб-приложение на базе фреймворка Litestar с использованием Dependency Injection, SQLAlchemy ORM, RabbitMQ для асинхронной обработки сообщений и Redis для кэширования данных о пользователях, продуктах и заказах.

## Оглавление

- [Быстрый старт](#быстрый-старт)
- [Установка и запуск](#установка-и-запуск)
  - [Вариант 1: Запуск через Docker Compose (Рекомендуется)](#вариант-1-запуск-через-docker-compose-рекомендуется)
  - [Вариант 2: Локальный запуск (для разработки)](#вариант-2-локальный-запуск-для-разработки)
- [Доступ к сервисам](#доступ-к-сервисам)
- [API Документация](#api-документация)
- [API Эндпоинты](#api-эндпоинты)
  - [Получить пользователя по ID](#получить-пользователя-по-id)
  - [Получить список пользователей](#получить-список-пользователей)
  - [Создать пользователя](#создать-пользователя)
  - [Обновить пользователя](#обновить-пользователя)
  - [Удалить пользователя](#удалить-пользователя)
- [Разработка](#разработка)
  - [Линтеры и форматеры](#линтеры-и-форматеры)
  - [Работа с Docker](#работа-с-docker)
  - [Доступ к базе данных](#доступ-к-базе-данных)
- [Структура данных](#структура-данных)
- [Обработка ошибок](#обработка-ошибок)

## Быстрый старт

```bash
# 1. Создайте .env файл (см. раздел "Установка и запуск")
# 2. Запустите всё одной командой:
docker compose up --build

# 3. Приложение доступно по адресу:
# http://localhost:8000
# http://localhost:8000/docs (API документация)
```

## Установка и запуск

### Вариант 1: Запуск через Docker Compose (Рекомендуется)
#### 1. Клонирование репозитория

```bash
git clone <repository_url>
cd lab2
```

#### 2. Настройка переменных окружения

Создайте файл `.env` в корне проекта:

```env
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin
POSTGRES_DB=lab_db2

PGADMIN_DEFAULT_EMAIL=admin@lab2.com
PGADMIN_DEFAULT_PASSWORD=admin

DB_HOST=db
DB_PORT=5432
HOST=0.0.0.0
PORT=8000

# RabbitMQ настройки
RABBITMQ_HOST=rabbitmq
RABBITMQ_PORT=5672
RABBITMQ_VHOST=local
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest

# Redis настройки
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_DECODE_RESPONSES=true
```

> **Примечание:** `DATABASE_URL` для контейнера настраивается автоматически в `docker-compose.yml`. Переменные `DB_HOST` и `DB_PORT` используются в `entrypoint.sh` для ожидания готовности базы данных.

#### 3. Сборка и запуск всех сервисов

```bash
# Сборка образа и запуск
docker compose up --build

# Или в фоновом режиме
docker compose up --build -d
```

Эта команда автоматически:
- Соберёт Docker образ приложения (используя `Dockerfile`)
- Запустит PostgreSQL базу данных
- Запустит PgAdmin
- Запустит RabbitMQ брокер сообщений
- Запустит Redis для кэширования
- Применит миграции базы данных через `entrypoint.sh`
- Запустит веб-приложение (REST API)
- Запустит RabbitMQ worker для обработки сообщений

**Примечание:** При первом запуске или при изменении `Dockerfile` используйте флаг `--build` для пересборки образа. Скрипт `entrypoint.sh` автоматически ожидает готовности базы данных и применяет миграции перед запуском приложения.

#### 4. Проверка статуса

```bash
docker compose ps
```

Все сервисы должны быть в статусе `Up`:
- `app_lab3` - веб-приложение (REST API) на порту `8000`
- `rabbitmq_worker_lab2` - RabbitMQ worker для обработки сообщений
- `db_postgres_lab2` - PostgreSQL на порту `5433`
- `pgadmin4_lab2` - PgAdmin на порту `8081`
- `rabbitmq_lab2` - RabbitMQ на портах `5672` (AMQP) и `15672` (Management UI)
- `redis` - Redis для кэширования на порту `6379`

#### 5. Просмотр логов

```bash
# Все логи
docker compose logs -f

# Только приложение
docker compose logs -f app

# Только база данных
docker compose logs -f db

# Только RabbitMQ
docker compose logs -f rabbitmq

# Только RabbitMQ worker
docker compose logs -f rabbitmq_worker

# Только Redis
docker compose logs -f redis
```

#### 6. Остановка сервисов

```bash
docker compose down
```

Для полной очистки (включая volumes):

```bash
docker compose down -v
```

---

### Вариант 2: Локальный запуск (для разработки)

без докера

#### 1. Клонирование репозитория

```bash
git clone <repository_url>
cd lab2
```

#### 2. Настройка переменных окружения

Создайте файл `.env` в корне проекта:

```env
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin
POSTGRES_DB=lab_db2

PGADMIN_DEFAULT_EMAIL=admin@lab2.com
PGADMIN_DEFAULT_PASSWORD=admin

DATABASE_URL=postgresql+asyncpg://admin:admin@localhost:5433/lab_db2
```

#### 3. Установка зависимостей

```bash
uv sync
```

#### 4. Запуск базы данных

```bash
docker compose up -d db pgadmin
```

Это запустит только:
- PostgreSQL на порту `5433`
- PgAdmin на порту `8081`

#### 5. Применение миграций

```bash
cd app
../.venv/bin/alembic upgrade head
cd ..
```

#### 6. Запуск приложения

```bash
python main.py
```

Приложение будет доступно по адресу: `http://localhost:8000`

---

### Доступ к сервисам

После запуска приложение и сервисы будут доступны по следующим адресам:

- **Веб-приложение**: http://localhost:8000
- **API документация (Swagger)**: http://localhost:8000/docs
- **PgAdmin**: http://localhost:8081
- **PostgreSQL**: localhost:5433
- **RabbitMQ Management UI**: http://localhost:15672 (логин: `guest`, пароль: `guest`)
- **RabbitMQ AMQP**: localhost:5672
- **Redis**: localhost:6379

## API Документация

После запуска приложения доступна интерактивная документация:

- **Swagger UI**: http://localhost:8000/docs
- **OpenAPI JSON**: http://localhost:8000/schema/openapi.json

## API Эндпоинты

### Получить пользователя по ID

```http
GET /users/{user_id}
```

**Параметры:**
- `user_id` (int, path) - ID пользователя (должен быть > 0)

**Ответ:**
- `200 OK` - Пользователь найден
- `404 Not Found` - Пользователь не найден

**Пример:**
```bash
curl http://localhost:8000/users/1
```

### Получить список пользователей

```http
GET /users?count=10&page=1
```

**Query параметры:**
- `count` (int, optional) - Количество записей на странице (1-100, по умолчанию 10)
- `page` (int, optional) - Номер страницы (≥1, по умолчанию 1)

**Ответ:**
```json
{
  "users": [
    {
      "id": 1,
      "username": "john_doe",
      "email": "john@example.com",
      "description": "Software developer",
      "created_at": "2024-01-01T12:00:00",
      "updated_at": "2024-01-02T10:00:00"
    }
  ],
  "total": 25
}
```

**Пример:**
```bash
curl "http://localhost:8000/users?count=5&page=2"
```

### Создать пользователя

```http
POST /users
Content-Type: application/json
```

**Тело запроса:**
```json
{
  "username": "jane_doe",
  "email": "jane@example.com",
  "description": "Designer"
}
```

**Ответ:**
- `201 Created` - Пользователь создан
- `400 Bad Request` - Ошибка валидации (email или username уже существует)
- `422 Unprocessable Entity` - Невалидные данные

**Пример:**
```bash
curl -X POST http://localhost:8000/users \
  -H "Content-Type: application/json" \
  -d '{
    "username": "jane_doe",
    "email": "jane@example.com",
    "description": "Designer"
  }'
```

### Обновить пользователя

```http
PUT /users/{user_id}
Content-Type: application/json
```

**Параметры:**
- `user_id` (int, path) - ID пользователя

**Тело запроса (все поля опциональные):**
```json
{
  "email": "newemail@example.com"
}
```

**Ответ:**
- `200 OK` - Пользователь обновлен
- `404 Not Found` - Пользователь не найден
- `400 Bad Request` - Email или username уже существует
- `422 Unprocessable Entity` - Невалидные данные

**Пример:**
```bash
curl -X PUT http://localhost:8000/users/1 \
  -H "Content-Type: application/json" \
  -d '{"email": "newemail@example.com"}'
```

### Удалить пользователя

```http
DELETE /users/{user_id}
```

**Параметры:**
- `user_id` (int, path) - ID пользователя

**Ответ:**
- `204 No Content` - Пользователь удален
- `404 Not Found` - Пользователь не найден

**Пример:**
```bash
curl -X DELETE http://localhost:8000/users/1
```

## Разработка

### Линтеры и форматеры

Проект использует `pre-commit` для автоматической проверки кода перед коммитом.

#### Установка pre-commit

```bash
# Установка хуков
uv run pre-commit install
```

#### Ручной запуск проверок

```bash
# Запуск всех проверок на всех файлах
uv run pre-commit run --all-files

# Форматирование кода
uv run black app

# Сортировка импортов
uv run isort app

# Проверка качества кода (без миграций)
uv run pylint app --ignore=migrations
```

#### Конфигурация

- **Black** и **isort**: настройки в `pyproject.toml`
- **Pylint**: настройки в `.pylintrc`
- **Pre-commit**: настройки в `.pre-commit-config.yaml`

Миграции Alembic исключены из проверки pylint, так как они генерируются автоматически.

### Работа с Docker

#### Сборка образа

```bash
# Сборка образа приложения
docker compose build

# Сборка с пересозданием кеша
docker compose build --no-cache
```

#### Entrypoint

При запуске контейнера используется `entrypoint.sh`, который:
1. Ожидает готовности базы данных (проверка через `netcat`)
2. Применяет миграции Alembic автоматически
3. Запускает приложение

#### Создание миграций

```bash
# В контейнере
docker compose exec app sh -c "cd app && uv run alembic revision --autogenerate -m 'описание изменений'"

# Локально
cd app
uv run alembic revision --autogenerate -m "описание изменений"
```

#### Перезапуск сервисов

```bash
# Перезапустить только приложение
docker compose restart app

# Перезапустить все сервисы
docker compose restart
```

### Доступ к базе данных

**Через PgAdmin:**
- URL: http://localhost:8081
- Email: admin@lab2.com
- Password: admin

### Доступ к Redis

**Через Redis CLI:**
```bash
# Подключение к Redis через Docker
docker compose exec redis redis-cli

# Или локально (если Redis доступен на localhost:6379)
redis-cli -h localhost -p 6379
```

**Полезные команды Redis CLI:**
```bash
# Проверка подключения
PING

# Просмотр всех ключей
KEYS *

# Просмотр ключей по шаблону
KEYS user:*
KEYS product:*

# Получение значения ключа
GET user:1

# Проверка TTL ключа (в секундах)
TTL user:1

# Просмотр информации о Redis
INFO

# Очистка всех данных (осторожно!)
FLUSHDB
```

**Переменные окружения для Redis:**
- `REDIS_HOST` - хост Redis (по умолчанию `redis` в Docker, `localhost` локально)
- `REDIS_PORT` - порт Redis (по умолчанию `6379`)
- `REDIS_DB` - номер базы данных (по умолчанию `0`)
- `REDIS_DECODE_RESPONSES` - автоматическая декодировка ответов в строки (по умолчанию `true`)

## Структура данных

### User (Пользователь)

| Поле | Тип | Описание |
|------|-----|----------|
| id | int | Уникальный идентификатор (autoincrement) |
| username | str | Имя пользователя (уникальное) |
| email | str | Email адрес (уникальный) |
| description | str \| None | Описание пользователя (опционально) |
| created_at | datetime | Дата и время создания |
| updated_at | datetime \| None | Дата и время последнего обновления |

## RabbitMQ

Проект использует RabbitMQ для асинхронной обработки сообщений о создании и обновлении продуктов и заказов.

### Архитектура

- **REST API** (Litestar): Получение данных (GET запросы)
- **RabbitMQ**: Создание и обновление данных (асинхронно через очереди)
- **RabbitMQ Worker**: Отдельный процесс для обработки сообщений из очередей

### Очереди

- `product` - очередь для создания продуктов
- `product_update` - очередь для обновления продуктов
- `order` - очередь для создания заказов
- `order_update` - очередь для обновления статуса заказов

### Использование Producer скрипта

Для отправки тестовых данных в RabbitMQ используйте producer скрипт:

```bash
# В Docker контейнере
docker compose exec app uv run python producer.py

# Локально (если RabbitMQ доступен на localhost:5672)
uv run python producer.py
```

Скрипт создаст:
- 5 тестовых продуктов
- 3 тестовых заказа

**Важно:** Перед запуском producer убедитесь, что в базе данных существуют:
- Пользователь с `user_id=1` (или установите `TEST_USER_ID` в переменных окружения)
- Адрес доставки с `delivery_address_id=1` (или установите `TEST_DELIVERY_ADDRESS_ID`)

### Веб-интерфейс RabbitMQ

Доступен по адресу: http://localhost:15672

- **Логин:** `guest`
- **Пароль:** `guest`

В интерфейсе можно:
- Просматривать очереди и их статистику
- Мониторить сообщения
- Проверять подключения и каналы

### Особенности обработки

1. **Создание заказов:**
   - Проверяется наличие всех товаров (`stock_quantity > 0`)
   - Если хотя бы один товар закончился (`stock_quantity == 0`), заказ отклоняется
   - При успешном создании заказа количество товаров на складе уменьшается

2. **Обновление продуктов:**
   - При обновлении проверяется, не закончился ли товар
   - Если `stock_quantity == 0`, в логах появляется предупреждение

3. **Получение данных:**
   - Все GET запросы работают через REST API (синхронно)
   - Создание и обновление доступно как через RabbitMQ, так и через REST API (для совместимости)

## Redis Кэширование

Проект использует Redis для кэширования данных пользователей и продукции, что значительно ускоряет доступ к часто запрашиваемым данным и снижает нагрузку на базу данных.

### Архитектура кэширования

Система использует стратегию **Cache-Aside** (Lazy Loading):

1. **При чтении данных:**
   - Сначала проверяется кэш Redis
   - Если данных нет в кэше (cache miss), запрос идет к базе данных
   - Полученные данные сохраняются в кэш для последующих запросов

2. **При обновлении пользователя:**
   - Обновление данных в базе данных
   - **Инвалидация кэша** (удаление данных из кэша)
   - При следующем запросе данные будут загружены из БД и сохранены в кэш

3. **При обновлении продукции:**
   - Обновление данных в базе данных
   - **Обновление кэша** (данные обновляются в кэше)
   - При следующем запросе данные сразу доступны из кэша

### Структура кэша

**Формат ключей:**
- Пользователи: `user:{id}` (например, `user:1`, `user:42`)
- Продукция: `product:{id}` (например, `product:1`, `product:100`)

**TTL (Time To Live):**
- **Пользователи**: 1 час (3600 секунд) - данные меняются редко
- **Продукция**: 10 минут (600 секунд) - данные могут меняться чаще

**Сериализация данных:**
- Данные хранятся в формате JSON
- Datetime объекты преобразуются в ISO строки для сериализации

### Преимущества кэширования

1. **Производительность:**
   - Запросы из кэша выполняются в разы быстрее, чем запросы к базе данных
   - Снижение нагрузки на PostgreSQL

2. **Масштабируемость:**
   - Redis может обрабатывать десятки тысяч запросов в секунду
   - Возможность горизонтального масштабирования

3. **Отказоустойчивость:**
   - При недоступности Redis приложение продолжает работать
   - Все запросы идут напрямую к базе данных
   - Ошибки кэширования не блокируют основную логику

### Стратегии инвалидации кэша

**Для пользователей (инвалидация):**
- При обновлении: данные удаляются из кэша
- При удалении: данные удаляются из кэша
- При следующем запросе: данные загружаются из БД и сохраняются в кэш

**Для продукции (обновление):**
- При обновлении: данные обновляются в кэше с новым TTL
- При удалении: данные удаляются из кэша
- При следующем запросе: данные сразу доступны из кэша

### Примеры использования Redis CLI

**Подключение к Redis:**
```bash
docker compose exec redis redis-cli
```

**Просмотр всех ключей:**
```bash
KEYS *
```

**Просмотр ключей пользователей:**
```bash
KEYS user:*
```

**Просмотр ключей продукции:**
```bash
KEYS product:*
```

**Проверка TTL ключа:**
```bash
# Для пользователя (должен быть ~3600 секунд)
TTL user:1

# Для продукции (должен быть ~600 секунд)
TTL product:1
```

**Просмотр значения ключа:**
```bash
# Получить данные пользователя
GET user:1

# Получить данные продукции
GET product:1
```

**Удаление ключа:**
```bash
DEL user:1
DEL product:1
```

**Проверка существования ключа:**
```bash
EXISTS user:1
```

**Просмотр информации о Redis:**
```bash
INFO
INFO memory
INFO stats
```

**Очистка всех данных (осторожно!):**
```bash
FLUSHDB
```

### Тестирование кэширования

Для тестирования кэширования используйте тестовый скрипт:

```bash
# Запуск тестов кэширования
uv run python test_redis_cache.py
```

Скрипт проверяет:
- Cache miss и cache hit для пользователей и продукции
- Инвалидацию кэша при обновлении пользователей
- Обновление кэша при обновлении продукции
- Корректность TTL для разных типов данных
- Производительность запросов с кэшем и без

### Мониторинг кэша

**Проверка статистики кэша:**
```bash
# В Redis CLI
INFO stats

# Просмотр количества ключей
DBSIZE

# Просмотр использования памяти
INFO memory
```

**Логирование:**
- Все операции с кэшем логируются в приложении
- Cache hits и cache misses логируются на уровне INFO/DEBUG
- Ошибки подключения к Redis логируются на уровне WARNING

## Обработка ошибок

| HTTP Статус | Описание |
|-------------|----------|
| 200 OK | Успешный запрос (GET, PUT) |
| 201 Created | Ресурс создан (POST) |
| 204 No Content | Ресурс удален (DELETE) |
| 400 Bad Request | Ошибка валидации (дублирующийся email/username) |
| 404 Not Found | Ресурс не найден |
| 422 Unprocessable Entity | Невалидные данные (Pydantic валидация) |
